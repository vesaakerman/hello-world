{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vesaakerman/hello-world/blob/master/notebooks/eBible_Download_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8dvXZnMNniY",
        "outputId": "86d01baf-2f2b-4a85-99c6-0df896e2ca10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define base folder"
      ],
      "metadata": {
        "id": "awnVICVNmGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"/content/drive/MyDrive/eBible/\""
      ],
      "metadata": {
        "id": "V-dpuImLmX4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Az2jLOoHPa"
      },
      "source": [
        "# Import modules and directory paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsAEZs5WoPbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6018b405-946f-4f4d-c667-a6adb3631003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ebible.org/Scriptures/\n",
            "https://ebible.org/Scriptures/translations.csv\n",
            "/content/drive/MyDrive/eBible/downloads\n",
            "/content/drive/MyDrive/eBible/projects\n",
            "/content/drive/MyDrive/eBible/projects\n",
            "/content/drive/MyDrive/eBible/metadata/translations.csv\n",
            "/content/drive/MyDrive/eBible/metadata/copyrights.csv\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import date, datetime\n",
        "from random import randint\n",
        "import requests\n",
        "from time import sleep\n",
        "import shutil\n",
        "from glob import iglob\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import DictReader, DictWriter\n",
        "import ntpath\n",
        "import regex\n",
        "\n",
        "eBible_url = r\"https://ebible.org/Scriptures/\"\n",
        "eBible_csv_url = r\"https://ebible.org/Scriptures/translations.csv\"\n",
        "\n",
        "zipped = Path(base) / \"downloads\"\n",
        "unzipped = Path(base) / \"projects\"\n",
        "ebible_projects = base + \"projects\"\n",
        "metadata = Path(base) / \"metadata\"\n",
        "metadata_csv = metadata / \"translations.csv\"\n",
        "copyright_file = metadata / \"copyrights.csv\"\n",
        "\n",
        "file_suffix = \"_usfm.zip\"\n",
        "headers = [\n",
        "    \"ID\",\n",
        "    \"File\",\n",
        "    \"Language\",\n",
        "    \"Dialect\",\n",
        "    \"Licence Type\",\n",
        "    \"Licence Version\",\n",
        "    \"CC Licence Link\",\n",
        "    \"Copyright Holder\",\n",
        "    \"Copyright Years\",\n",
        "    \"Translation by\",\n",
        "]\n",
        "\n",
        "print(eBible_url)\n",
        "print(eBible_csv_url)\n",
        "print(zipped)\n",
        "print(unzipped)\n",
        "print(ebible_projects)\n",
        "print(metadata_csv)\n",
        "print(copyright_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdkvOPbzdMg"
      },
      "source": [
        "# Define methods for downloading and unzipping eBibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHI0bcJYz6ID"
      },
      "outputs": [],
      "source": [
        "def log_and_print(s, type='Ã­nfo'):\n",
        "    if type == \"error\":\n",
        "        log_file.write(f\"ERROR: {datetime.now()} {s}\\n\")\n",
        "    else:\n",
        "        log_file.write(f\"INFO: {datetime.now()} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "def make_directories():\n",
        "    os.makedirs(zipped, exist_ok=True)\n",
        "    os.makedirs(unzipped, exist_ok=True)\n",
        "    os.makedirs(metadata, exist_ok=True)\n",
        "\n",
        "\n",
        "def download_csv_file(url, headers, save_as):\n",
        "\n",
        "    r = requests.get(url, headers=headers)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "\n",
        "        with open(save_as, \"wb\") as out_file:\n",
        "            # Write out the content of the page.\n",
        "            out_file.write(r.content)\n",
        "\n",
        "        return save_as\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_csv_file(csv_url, save_as):\n",
        "    log_and_print(f\"Saving file from {csv_url} to {zips_folder}\")\n",
        "\n",
        "    r = requests.get(csv_url)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "\n",
        "        with open(save_as, \"wb\") as csv_file:\n",
        "            csv_file.write(r.content)\n",
        "        return save_as\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def download_zip_file(url, headers, save_as):\n",
        "\n",
        "    r = requests.get(url, headers=headers)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "\n",
        "        with open(save_as, \"wb\") as out_file:\n",
        "            # Write out the content of the page.\n",
        "            out_file.write(r.content)\n",
        "\n",
        "        return save_as\n",
        "    return None\n",
        "    \n",
        "def get_folder(file):\n",
        "    # Get the path of the folder to which the zip file should be extracted.\"\n",
        "    return unzipped / file.name[0: (len(file.name) - len(file_suffix))]\n",
        "\n",
        "\n",
        "def get_tree_size(path):\n",
        "    \"\"\"Return total size of files in given path and subdirs.\"\"\"\n",
        "    total = 0\n",
        "    for entry in os.scandir(path):\n",
        "        if entry.is_dir(follow_symlinks=False):\n",
        "            total += get_tree_size(entry.path)\n",
        "        else:\n",
        "            total += entry.stat(follow_symlinks=False).st_size\n",
        "    return total\n",
        "    \n",
        "    \n",
        "def unzip_ebibles(source_folder, file_suffix, dest_folder):\n",
        "    pattern = \"*\" + file_suffix\n",
        "    zip_files = [zip_file for zip_file in source_folder.glob(pattern)]\n",
        "    \n",
        "    # Strip off the pattern so that the subfolder name is the project ID.\n",
        "    extract_folders = [ (zip_file, get_folder(zip_file)) for zip_file in zip_files ]\n",
        "    extracts = [ (zip_file, folder) for zip_file, folder in extract_folders if not folder.exists() or zip_file.stat().st_size >= get_tree_size(folder) ]\n",
        "    log_and_print(f\"Found {len(zip_files)} files in {source_folder} matching pattern: {pattern}\")\n",
        "    log_and_print(f\"Found {len(extracts)} that were not yet extracted or are smaller than the zip file.\")\n",
        "    \n",
        "    for zip_file, extract in extracts:\n",
        "        extract.mkdir(parents=True, exist_ok=True)\n",
        "        log_and_print(f\"Extracting to: {extract}\")\n",
        "        shutil.unpack_archive(zip_file, extract)\n",
        "\n",
        "def get_filenames(metadata_csv):\n",
        "    file_infos = []\n",
        "    countall = count_redist = 0\n",
        "\n",
        "    with open(metadata_csv, encoding=\"utf-8-sig\", newline=\"\") as csvfile:\n",
        "        reader = DictReader(csvfile, delimiter=\",\", quotechar='\"')\n",
        "        for row in reader:\n",
        "            countall += 1\n",
        "            if row[\"Redistributable\"] == \"True\":\n",
        "                row[\"Redistributable\"] = True\n",
        "\n",
        "                file_infos.append(row)\n",
        "                count_redist += 1\n",
        "\n",
        "            if row[\"Redistributable\"] == \"False\":\n",
        "                row[\"Redistributable\"] = False\n",
        "\n",
        "                file_infos.append(row)\n",
        "\n",
        "        filenames = [row[\"translationId\"] + file_suffix for row in file_infos]\n",
        "        log_and_print(f\"The translations csv file lists {countall} translations and {count_redist} are redistributable.\")\n",
        "\n",
        "        return filenames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oQDn6UjoYw1"
      },
      "source": [
        "# Download and unzip eBible projects "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJxJjQnsvx_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802c6d3b-acc8-4563-e5fc-04948d2788b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading list of translations from https://ebible.org/Scriptures/translations.csv to: /content/drive/MyDrive/eBible/metadata/translations.csv\n",
            "The translations csv file lists 1284 translations and 1035 are redistributable.\n",
            "There are 2 files with the suffix _usfm.zip already in /content/drive/MyDrive/eBible/downloads\n",
            "\n",
            "There are 1282 files still to download.\n",
            "1: Downloading from https://ebible.org/Scriptures/ebk_usfm.zip to /content/drive/MyDrive/eBible/downloads/ebk_usfm.zip.\n",
            "Saved https://ebible.org/Scriptures/ebk_usfm.zip as /content/drive/MyDrive/eBible/downloads/ebk_usfm.zip\n",
            "\n",
            "Found 3 files in /content/drive/MyDrive/eBible/downloads matching pattern: *_usfm.zip\n",
            "Found 1 that were not yet extracted or are smaller than the zip file.\n",
            "Extracting to: /content/drive/MyDrive/eBible/projects/ebk\n"
          ]
        }
      ],
      "source": [
        "log_file = open(zipped / f\"run_{date.today()}.log\", \"a\")\n",
        "\n",
        "# Set the user-agent to Chrome for Requests.\n",
        "headers = {\"user-agent\": \"Chrome/51.0.2704.106\"}\n",
        "\n",
        "# Create directories if they don't already exist\n",
        "make_directories()\n",
        "\n",
        "# Download the list of translations.\n",
        "log_and_print(f\"Downloading list of translations from {eBible_csv_url} to: {str(metadata_csv)}\")\n",
        "done = download_csv_file(eBible_csv_url, headers, metadata_csv)\n",
        "if not done:\n",
        "    log_and_print(f\"Couldn't download {eBible_csv_url}\")\n",
        "    exit\n",
        "\n",
        "# Get filenames\n",
        "filenames = get_filenames(metadata_csv)\n",
        "\n",
        "# Find which files have already been downloaded:\n",
        "already_downloaded = [file.name for file in zipped.glob(\"*\" + file_suffix)]\n",
        "log_and_print(f\"There are {len(already_downloaded)} files with the suffix {file_suffix} already in {zipped}\")\n",
        "\n",
        "# Those that require downloading are the filenames - already_downloaded.\n",
        "to_download = set(filenames) - set(already_downloaded)\n",
        "log_and_print(f\"\\nThere are {len(to_download)} files still to download.\")\n",
        "\n",
        "# Download the zipped USFM file if it doesn't already exist.\n",
        "\n",
        "for i, filename in enumerate(to_download):\n",
        "\n",
        "    if i < 1:\n",
        "\n",
        "      # Construct the download url and the local file path.\n",
        "      url = eBible_url + filename\n",
        "      save_as = zipped / filename\n",
        "\n",
        "      # Skip any missing filenames.\n",
        "      if filename == \"\":\n",
        "          continue\n",
        "\n",
        "      # Skip existing files that contain data.\n",
        "      elif save_as.exists() and save_as.stat().st_size > 100:\n",
        "          log_and_print(f\"{i+1}: {save_as} already exists and contains {save_as.stat().st_size} bytes.\")\n",
        "          continue\n",
        "\n",
        "      else:\n",
        "          log_and_print(f\"{i+1}: Downloading from {url} to {save_as}.\")\n",
        "          done = download_zip_file(url, headers, save_as)\n",
        "\n",
        "          if done:\n",
        "              log_and_print(f\"Saved {url} as {save_as}\\n\")\n",
        "              # Pause for a random number of miliseconds\n",
        "              pause = randint(1, 5000) / 1000\n",
        "              sleep(pause)\n",
        "\n",
        "          else:\n",
        "              log_and_print(f\"Could not download {url}\\n\")\n",
        "log_file.close()\n",
        "\n",
        "log_file = open(unzipped / f\"run_{date.today()}.log\", \"a\")\n",
        "unzip_ebibles(zipped, file_suffix, unzipped)\n",
        "\n",
        "log_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define methods for creating the copyrights file"
      ],
      "metadata": {
        "id": "zOCUTLeCCK4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def path_leaf(path):\n",
        "    head, tail = ntpath.split(path)\n",
        "    return tail or ntpath.basename(head)\n",
        "\n",
        "\n",
        "def read_list_from_file(f_in):\n",
        "    lines = list()\n",
        "    with open(f_in, \"r\", encoding=\"utf-8\") as infile:\n",
        "        for line in infile.read().splitlines():\n",
        "            lines.append(line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def get_copyright_from_url(url):\n",
        "    r = requests.get(url)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "        soup = BeautifulSoup(r.content, \"lxml\")\n",
        "        cr_item = soup.find(\"td\", colspan=\"3\")\n",
        "        return cr_item.string\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "pQdjZvMhCgpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxGefMIC0XB"
      },
      "source": [
        "# Get copyright info from eBible projects "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = open(metadata / f\"run_{date.today()}.log\", \"a\")\n",
        "\n",
        "data = list()\n",
        "copr_regex = r\".*/(?P<id>.*?)/copr.htm\"\n",
        "\n",
        "# Check we can write to the output file before the processing:\n",
        "with open(copyright_file, 'w',encoding='utf-8') as f_out:\n",
        "    pass\n",
        "\n",
        "log_and_print(\"Collecting eBible copyright information...\")\n",
        "for copyright_info_file in sorted(iglob(ebible_projects + \"/**/copr.htm\")):\n",
        "    log_and_print(copyright_info_file)\n",
        "\n",
        "    id_match = regex.match(copr_regex, str(copyright_info_file))\n",
        "    id = id_match[\"id\"]\n",
        "\n",
        "    entry = dict()\n",
        "    entry[\"ID\"] = str(id)\n",
        "    entry[\"File\"] = copyright_info_file\n",
        "\n",
        "    with open(copyright_info_file, \"r\", encoding=\"utf-8\") as copr:\n",
        "        html = copr.read()\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    cclink = soup.find(href=regex.compile(\"creativecommons\"))\n",
        "    if cclink:\n",
        "        ref = cclink.get(\"href\")\n",
        "        if ref:\n",
        "            entry[\"CC Licence Link\"] = ref\n",
        "            cc_match = regex.match(\n",
        "                r\".*?/licenses/(?P<type>.*?)/(?P<version>.*)/\", ref\n",
        "            )\n",
        "            if cc_match:\n",
        "                entry[\"Licence Type\"] = cc_match[\"type\"]\n",
        "                entry[\"Licence Version\"] = cc_match[\"version\"]\n",
        "            else:\n",
        "                cc_by_match = regex.match(r\".*?/licenses/by(?P<version>.*)/\", ref)\n",
        "                if cc_by_match:\n",
        "                    # print(f'Licence version = {cc_by_match[\"version\"]}')\n",
        "                    entry[\"Licence Type\"] = \"by\"\n",
        "                    entry[\"Licence Version\"] = cc_by_match[\"version\"]\n",
        "\n",
        "    cclink = None\n",
        "\n",
        "    titlelink = soup.find(href=regex.compile(f\"https://ebible.org/{id}\"))\n",
        "    if titlelink:\n",
        "        entry[\"Vernacular Title\"] = titlelink.string\n",
        "    titlelink = None\n",
        "\n",
        "    copy_strings = [s for s in soup.body.p.stripped_strings]\n",
        "      \n",
        "    for i, copy_string in enumerate(copy_strings):\n",
        "        if i == 0 and \"copyright Â©\" in copy_string:\n",
        "            entry[\"Copyright Years\"] = copy_string\n",
        "            entry[\"Copyright Holder\"] = copy_strings[i + 1]\n",
        "        if i > 0 and \"Language:\" in copy_string:\n",
        "            entry[\"Language\"] = copy_strings[i + 1]\n",
        "        if \"Dialect\" in copy_string:\n",
        "            entry[\"Dialect\"] = copy_string\n",
        "        if \"Translation by\" in copy_string:\n",
        "            entry[\"Translation by\"] = copy_string\n",
        "        if \"Public Domain\" in copy_string:\n",
        "            entry[\"Copyright Year\"] = \"\"\n",
        "            entry[\"Copyright Holder\"] = \"Public Domain\"\n",
        "    \n",
        "    data.append(entry)\n",
        "\n",
        "    with open(copyright_file, \"w\", encoding=\"utf-8\") as csv_out:\n",
        "        writer = DictWriter(\n",
        "            csv_out, headers, restval=\"\", extrasaction=\"ignore\", dialect=\"excel\"\n",
        "        )\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "log_and_print(f\"Wrote copyright info to {copyright_file}\")\n",
        "log_file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2MnbSVEC4tY",
        "outputId": "f59072be-dd36-43f8-88f4-9c7b34c76760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eBible copyright information...\n",
            "/content/drive/MyDrive/eBible/projects/bjvNT/copr.htm\n",
            "/content/drive/MyDrive/eBible/projects/ebk/copr.htm\n",
            "/content/drive/MyDrive/eBible/projects/engWycliffe/copr.htm\n",
            "Wrote copyright info to /content/drive/MyDrive/eBible/metadata/copyrights.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}