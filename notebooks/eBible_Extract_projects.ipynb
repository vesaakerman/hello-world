{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vesaakerman/hello-world/blob/master/notebooks/eBible_Extract_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8dvXZnMNniY",
        "outputId": "387c4526-0f43-4ea6-b39c-2b38a08c22e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define base folder"
      ],
      "metadata": {
        "id": "awnVICVNmGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible\""
      ],
      "metadata": {
        "id": "V-dpuImLmX4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Az2jLOoHPa"
      },
      "source": [
        "# Import modules, define rewrite boolean and directory paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsAEZs5WoPbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc8c6c7-6fe9-4eab-be39-dadc9d5ab475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/downloads\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/extractions/scripture\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/metadata/translations.csv\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/logs\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/temp\n",
            "rewrite = False\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datetime import date, datetime\n",
        "from os import listdir, makedirs, environ\n",
        "from os.path import exists\n",
        "from glob import iglob\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import warnings\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import codecs\n",
        "import regex\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "rewrite = False  # tells if the project is overwritten when it already exists\n",
        "\n",
        "corpus = Path(base)\n",
        "\n",
        "ebible_downloads = corpus / 'downloads'\n",
        "ebible_extractions = corpus / \"extractions/scripture\"\n",
        "ebible_translations_csv = corpus / 'metadata/translations.csv'\n",
        "ebible_logs = corpus / \"logs\"\n",
        "ebible_temp = corpus / \"temp\"\n",
        "\n",
        "print(ebible_downloads)\n",
        "print(ebible_extractions)\n",
        "print(ebible_translations_csv)\n",
        "print(ebible_logs)\n",
        "print(ebible_temp)\n",
        "print(f\"rewrite = {rewrite}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages and clone the silnlp repo"
      ],
      "metadata": {
        "id": "wk_2lgrHjLGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install sil-machine\n",
        "!pip install boto3\n",
        "!pip install s3path\n",
        "!pip install requests\n",
        "\n",
        "!git clone https://github.com/sillsdev/silnlp"
      ],
      "metadata": {
        "id": "cpIB4aWzjUpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b2e7d9-df7a-40e3-b8b2-dddc917ee005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sil-machine in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.6.3)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (3.0.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (1.21.6)\n",
            "Requirement already satisfied: regex<2022.0.0,>=2021.7.6 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2021.11.10)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.26.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.29.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.1->boto3) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.1->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.1->boto3) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: s3path in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from s3path) (5.2.1)\n",
            "Requirement already satisfied: boto3>=1.16.35 in /usr/local/lib/python3.7/dist-packages (from s3path) (1.26.1)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.29.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.1->boto3>=1.16.35->s3path) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.1->boto3>=1.16.35->s3path) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.1->boto3>=1.16.35->s3path) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.25.11)\n",
            "fatal: destination path 'silnlp' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdkvOPbzdMg"
      },
      "source": [
        "# Define methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHI0bcJYz6ID"
      },
      "outputs": [],
      "source": [
        "def improve_column_names(df): df.columns = df.columns.str.strip().str.lower().str.replace('\"', '').str.replace(\"'\", '')\\\n",
        "    .str.replace('(', '').str.replace(')', '').str.replace(' ', '_')\n",
        "\n",
        "\n",
        "def log_and_print(s, type='ínfo'):\n",
        "    log_file.write(f\"{type.upper()}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "\n",
        "def get_copyrights(project):\n",
        "\n",
        "    copyright_info_file = project / \"copr.htm\"\n",
        "\n",
        "    license_type = None\n",
        "    copyright_holder = None\n",
        "    cclink = None\n",
        "\n",
        "    with open(copyright_info_file, \"r\", encoding=\"utf-8\") as copr:\n",
        "        html = copr.read()\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    cclink = soup.find(href=regex.compile(\"creativecommons\"))\n",
        "    if cclink:\n",
        "        ref = cclink.get(\"href\")\n",
        "        if ref:\n",
        "            cc_match = regex.match(\n",
        "                r\".*?/licenses/(?P<type>.*?)/(?P<version>.*)/\", ref\n",
        "            )\n",
        "            if cc_match:\n",
        "                license_type = cc_match[\"type\"]\n",
        "            else:\n",
        "                cc_by_match = regex.match(r\".*?/licenses/by(?P<version>.*)/\", ref)\n",
        "                if cc_by_match:\n",
        "                    license_type = \"by\"\n",
        "\n",
        "    copy_strings = [s for s in soup.body.p.stripped_strings]\n",
        "      \n",
        "    for i, copy_string in enumerate(copy_strings):\n",
        "        if i == 0 and \"copyright ©\" in copy_string:\n",
        "            copyright_holder = copy_strings[i + 1]\n",
        "        if \"Public Domain\" in copy_string:\n",
        "            copyright_holder = \"Public Domain\"\n",
        "\n",
        "    return license_type, copyright_holder\n",
        "\n",
        "\n",
        "def get_extracted_projects(dir_extracted):\n",
        "\n",
        "    extracted = []\n",
        "    for line in listdir(dir_extracted):\n",
        "        m = re.search(r\".+-(.+).txt$\", line)\n",
        "        if m:\n",
        "            extracted.append(m.group(1))\n",
        "    \n",
        "    return extracted\n",
        "\n",
        "\n",
        "def get_books_type(files):\n",
        "\n",
        "    for book in files:\n",
        "        m = re.search(r\".*GEN|JON.*\", book)\n",
        "        if m:\n",
        "            return \"OT+NT\"\n",
        "    return \"NT\"\n",
        "\n",
        "\n",
        "def get_conclusion(versification):\n",
        "\n",
        "    if versification != \"\":\n",
        "        return versification\n",
        "    else:\n",
        "        return \"4\" # English\n",
        "\n",
        "\n",
        "def conclude_versification_from_OT(dan_3, dan_5, dan_13):\n",
        "    if dan_3 == 30:\n",
        "        versification = \"4\"  # English\n",
        "    elif dan_3 == 33 and dan_5 == 30:\n",
        "        versification = \"1\"  # Original\n",
        "    elif dan_3 == 33 and dan_5 == 31:\n",
        "        versification = \"5\"  # Russian Protestant\n",
        "    elif dan_3 == 97:\n",
        "        versification = \"2\"  # Septuagint\n",
        "    elif dan_3 == 100:\n",
        "        if dan_13 == 65:\n",
        "            versification = \"3\"  # Vulgate\n",
        "        else:\n",
        "            versification = \"6\"  # Russian Orthodox\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def conclude_versification_from_NT(jhn_6, act_19, rom_16):\n",
        "    if jhn_6 == 72:\n",
        "        versification = \"3\"  # Vulgate\n",
        "    elif act_19 == 41:\n",
        "        versification = \"4\"  # English\n",
        "    elif rom_16 == 24:\n",
        "        versification = \"6\"  # Russian Orthodox (same as Russian Protestant)\n",
        "    elif jhn_6 == 71 and act_19 == 40:\n",
        "        versification = \"1\"  # Original (Same as Septuagint)\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def get_last_verse(project, book, chapter):\n",
        "\n",
        "    ch = str(chapter)\n",
        "\n",
        "    for book_file in iglob(f\"{project}/*{book}*\"):\n",
        "        last_verse = \"0\"\n",
        "        try:\n",
        "            f = codecs.open(book_file, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not open {book_file}, reason:  {e}\")\n",
        "            continue\n",
        "        try:\n",
        "            in_chapter = False\n",
        "            for line in f:\n",
        "                m = re.search(r\"\\\\c ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if m.group(1) == ch:\n",
        "                        in_chapter = True\n",
        "                    else:\n",
        "                        in_chapter = False\n",
        "\n",
        "                m = re.search(r\"\\\\v ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if in_chapter:\n",
        "                        last_verse = m.group(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Something went wrong in reading {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "        try:\n",
        "            return int(last_verse)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not convert {last_verse} into an integer in {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "def get_checkpoints_OT(project):\n",
        "    dan_3 = get_last_verse(project, \"DAN\", 3)\n",
        "    dan_5 = get_last_verse(project, \"DAN\", 5)\n",
        "    dan_13 = get_last_verse(project, \"DAN\", 13)\n",
        "\n",
        "    return dan_3, dan_5, dan_13\n",
        "\n",
        "\n",
        "def get_checkpoints_NT(project):\n",
        "    jhn_6 = get_last_verse(project, \"JHN\", 6)\n",
        "    act_19 = get_last_verse(project, \"ACT\", 19)\n",
        "    rom_16 = get_last_verse(project, \"ROM\", 16)\n",
        "\n",
        "    return jhn_6, act_19, rom_16\n",
        "\n",
        "\n",
        "def get_versification(project):\n",
        "    versification = \"\"\n",
        "    books = get_books_type(listdir(project))\n",
        "\n",
        "    if books == \"OT+NT\":\n",
        "        dan_3, dan_5, dan_13 = get_checkpoints_OT(project)\n",
        "        versification = conclude_versification_from_OT(dan_3, dan_5, dan_13)\n",
        "\n",
        "    if not versification:\n",
        "        jhn_6, act_19, rom_16 = get_checkpoints_NT(project)\n",
        "        versification = conclude_versification_from_NT(jhn_6, act_19, rom_16)\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def add_settings_file(project, language_code):\n",
        "    versification = get_conclusion(get_versification(project))\n",
        "\n",
        "    root = ET.Element(\"ScriptureText\")\n",
        "    ET.SubElement(root, \"Versification\").text = versification\n",
        "    ET.SubElement(root, \"LanguageIsoCode\").text = language_code + \":::\"\n",
        "    ET.SubElement(root, \"Naming\", BookNameForm = \"41-MAT\", PostPart = project.name + \".usfm\", PrePart = \"\")\n",
        "    ET.ElementTree(root).write(project / \"Settings.xml\")\n",
        "\n",
        "\n",
        "def get_language_code(project):\n",
        "\n",
        "    translations = pd.read_csv(ebible_translations_csv)\n",
        "    improve_column_names(translations)\n",
        "    translations.set_index(\"translationid\", inplace = True)\n",
        "    language_code = translations.loc[project.name]['languagecode']\n",
        "\n",
        "    return language_code\n",
        "\n",
        "\n",
        "def is_redistributable(project):\n",
        "\n",
        "    ok_copyrights = [\"by-nc-nd\", \"by-nd\", \"by-sa\"]\n",
        "\n",
        "    translations = pd.read_csv(ebible_translations_csv)\n",
        "    improve_column_names(translations)\n",
        "    translations.set_index(\"translationid\", inplace = True)\n",
        "    redistributable = translations.loc[project.name]['redistributable']\n",
        "    licence_type, copyright_holder = get_copyrights(project)\n",
        "\n",
        "    return redistributable and (licence_type in ok_copyrights or copyright_holder == \"Public Domain\")\n",
        "\n",
        "\n",
        "def unzip(zip, unzip):\n",
        "    unzip.mkdir(parents=True, exist_ok=True)\n",
        "    shutil.unpack_archive(zip, unzip)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract projects"
      ],
      "metadata": {
        "id": "0nJMFLIvMAIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = open(ebible_logs / f\"run_{date.today()}.log\", \"a\")\n",
        "log_and_print(f\"Starting extracting eBible projects...\")\n",
        "\n",
        "# Tell the SIL NLP tools where to find the resources\n",
        "environ['SIL_NLP_DATA_PATH'] = base\n",
        "environ['SIL_NLP_MT_DIR'] = \"extractions\"\n",
        "\n",
        "# Tell Python where to find our repo\n",
        "environ['PYTHONPATH'] = \"/env/python:/content/silnlp\"\n",
        "\n",
        "makedirs(ebible_extractions, exist_ok=True)\n",
        "makedirs(ebible_temp, exist_ok=True)\n",
        "\n",
        "extracted = get_extracted_projects(ebible_extractions)\n",
        "nr_extracted = len(extracted)\n",
        "\n",
        "for download in sorted(ebible_downloads.glob(\"[a-zA-Z0-9]*\")):\n",
        "    name = download.name[0:download.name.find(\"_usfm.zip\")]\n",
        "    if not name in extracted or rewrite:\n",
        "        project = ebible_temp / name\n",
        "        unzip(download, project)\n",
        "        if is_redistributable(project):\n",
        "            log_and_print(f\"extracting {project}\")\n",
        "            add_settings_file(project, get_language_code(project))\n",
        "            !python -m silnlp.common.extract_corpora \"{project}\"\n",
        "            shutil.rmtree(project)\n",
        "            break\n",
        "\n",
        "log_and_print(f\"{len(get_extracted_projects(ebible_extractions)) - nr_extracted} new eBible projects extracted\")\n",
        "log_and_print(f\"Rewrite {rewrite}\")\n",
        "log_file.close()\n",
        "shutil.rmtree(ebible_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "r17FtPQpJBeJ",
        "outputId": "dac93b70-33c8-4eaf-93c5-2c3e96e89ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting extracting eBible projects...\n",
            "These are the initial column names: Index(['languageCode', 'translationId', 'languageName',\n",
            "       'languageNameInEnglish', 'dialect', 'homeDomain', 'title',\n",
            "       'description', 'Redistributable', 'Copyright', 'UpdateDate',\n",
            "       'publicationURL', 'OTbooks', 'OTchapters', 'OTverses', 'NTbooks',\n",
            "       'NTchapters', 'NTverses', 'DCbooks', 'DCchapters', 'DCverses', 'FCBHID',\n",
            "       'Certified', 'inScript', 'swordName', ' \"rodCode\"', ' \"textDirection\"',\n",
            "       ' \"downloadable\"', ' \"font\"', ' \"shortTitle\"', ' \"PODISBN\"',\n",
            "       ' \"script\"'],\n",
            "      dtype='object')\n",
            "These are the fixed column names: Index(['languagecode', 'translationid', 'languagename',\n",
            "       'languagenameinenglish', 'dialect', 'homedomain', 'title',\n",
            "       'description', 'redistributable', 'copyright', 'updatedate',\n",
            "       'publicationurl', 'otbooks', 'otchapters', 'otverses', 'ntbooks',\n",
            "       'ntchapters', 'ntverses', 'dcbooks', 'dcchapters', 'dcverses', 'fcbhid',\n",
            "       'certified', 'inscript', 'swordname', 'rodcode', 'textdirection',\n",
            "       'downloadable', 'font', 'shorttitle', 'podisbn', 'script'],\n",
            "      dtype='object')\n",
            "extracting /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/temp/aai\n",
            "2022-11-03 14:17:04,087 - silnlp.common.environment - INFO - Using workspace: /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible as per environment variable SIL_NLP_DATA_PATH.\n",
            "2022-11-03 14:17:04,125 - silnlp.common.extract_corpora - INFO - Extracting /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/temp/aai...\n",
            "2022-11-03 14:17:10,847 - silnlp.common.extract_corpora - INFO - # of Verses: 41899\n",
            "2022-11-03 14:17:10,848 - silnlp.common.extract_corpora - INFO - # of Terms: 0\n",
            "2022-11-03 14:17:10,848 - silnlp.common.extract_corpora - INFO - Done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-61b5828bae44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0madd_settings_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_language_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -m silnlp.common.extract_corpora \"{project}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/temp/aai'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}