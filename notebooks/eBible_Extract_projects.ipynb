{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vesaakerman/hello-world/blob/master/notebooks/eBible_Extract_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8dvXZnMNniY",
        "outputId": "7de7cff3-ccd7-4912-86d6-438edb28560a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define base folder"
      ],
      "metadata": {
        "id": "awnVICVNmGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base = \"/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible\"\n",
        "base = \"/content/drive/MyDrive/eBible\""
      ],
      "metadata": {
        "id": "V-dpuImLmX4J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Az2jLOoHPa"
      },
      "source": [
        "# Import modules, define rewrite boolean and directory paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JsAEZs5WoPbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77115483-758b-4c03-b34d-8de2cb0a0556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/eBible/downloads\n",
            "/content/drive/MyDrive/eBible/extractions/scripture\n",
            "/content/drive/MyDrive/eBible/metadata/translations.csv\n",
            "/content/drive/MyDrive/eBible/metadata/copyrights.csv\n",
            "/content/drive/MyDrive/eBible/logs\n",
            "/content/drive/MyDrive/eBible/temp\n",
            "rewrite = False\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datetime import date, datetime\n",
        "from os import listdir, makedirs, environ\n",
        "from os.path import exists\n",
        "from glob import iglob\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import warnings\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import codecs\n",
        "import regex\n",
        "import csv\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "rewrite = False  # tells if the project is overwritten when it already exists\n",
        "\n",
        "corpus = Path(base)\n",
        "\n",
        "ebible_downloads = corpus / 'downloads'\n",
        "ebible_extractions = corpus / \"extractions/scripture\"\n",
        "ebible_translations_csv = corpus / 'metadata/translations.csv'\n",
        "ebible_copyrights_csv = corpus / 'metadata/copyrights.csv'\n",
        "ebible_logs = corpus / \"logs\"\n",
        "ebible_temp = corpus / \"temp\"\n",
        "\n",
        "print(ebible_downloads)\n",
        "print(ebible_extractions)\n",
        "print(ebible_translations_csv)\n",
        "print(ebible_copyrights_csv)\n",
        "print(ebible_logs)\n",
        "print(ebible_temp)\n",
        "print(f\"rewrite = {rewrite}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages and clone the silnlp repo"
      ],
      "metadata": {
        "id": "wk_2lgrHjLGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install sil-machine\n",
        "!pip install boto3\n",
        "!pip install s3path\n",
        "!pip install requests\n",
        "\n",
        "!git clone https://github.com/sillsdev/silnlp"
      ],
      "metadata": {
        "id": "cpIB4aWzjUpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a87b61a-0a07-4280-a683-2416f6075bd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sil-machine\n",
            "  Downloading sil_machine-0.8.4-py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0.0,>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.1.1)\n",
            "Collecting regex<2022.0.0,>=2021.7.6\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (1.21.6)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.6.3)\n",
            "Installing collected packages: regex, sil-machine\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "Successfully installed regex-2021.11.10 sil-machine-0.8.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "regex"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.19-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.19\n",
            "  Downloading botocore-1.29.19-py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 63.4 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.19->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.19->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.26.19 botocore-1.29.19 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting s3path\n",
            "  Downloading s3path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from s3path) (5.2.1)\n",
            "Requirement already satisfied: boto3>=1.16.35 in /usr/local/lib/python3.7/dist-packages (from s3path) (1.26.19)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.19 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.29.19)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.19->boto3>=1.16.35->s3path) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.19->boto3>=1.16.35->s3path) (1.26.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.19->boto3>=1.16.35->s3path) (1.15.0)\n",
            "Installing collected packages: s3path\n",
            "Successfully installed s3path-0.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.13\n",
            "    Uninstalling urllib3-1.26.13:\n",
            "      Successfully uninstalled urllib3-1.26.13\n",
            "Successfully installed urllib3-1.25.11\n",
            "Cloning into 'silnlp'...\n",
            "remote: Enumerating objects: 4845, done.\u001b[K\n",
            "remote: Counting objects: 100% (778/778), done.\u001b[K\n",
            "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
            "remote: Total 4845 (delta 565), reused 679 (delta 497), pack-reused 4067\u001b[K\n",
            "Receiving objects: 100% (4845/4845), 11.71 MiB | 15.65 MiB/s, done.\n",
            "Resolving deltas: 100% (3444/3444), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdkvOPbzdMg"
      },
      "source": [
        "# Define methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mHI0bcJYz6ID"
      },
      "outputs": [],
      "source": [
        "def improve_column_names(df): df.columns = df.columns.str.strip().str.lower().str.replace('\"', '').str.replace(\"'\", '')\\\n",
        "    .str.replace('(', '').str.replace(')', '').str.replace(' ', '_')\n",
        "\n",
        "\n",
        "def log_and_print(s, type='ínfo'):\n",
        "    log_file.write(f\"{type.upper()}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "\n",
        "def write_copyrights(translation_id, license_type, copyright_holder):\n",
        "\n",
        "    if not exists(ebible_copyrights_csv):\n",
        "        header = ['translationId', 'licenseType', 'copyrightHolder']\n",
        "        with open(ebible_copyrights_csv, 'w', encoding='UTF8') as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "            f.close()\n",
        "\n",
        "    df = pd.read_csv(ebible_copyrights_csv)\n",
        "    t_ids = df.set_index(\"translationId\")\n",
        "    if translation_id in t_ids.index:\n",
        "        df.loc[df['translationId'] == translation_id, 'licenseType'] = license_type\n",
        "        df.loc[df['translationId'] == translation_id, 'copyrightHolder'] = copyright_holder\n",
        "    else:\n",
        "        new_row = {'translationId':translation_id, 'licenseType':license_type, 'copyrightHolder':copyright_holder}\n",
        "        df = df.append(new_row, ignore_index=True)\n",
        "    df = df.sort_values(by=['translationId'])\n",
        "    df.to_csv(ebible_copyrights_csv, index=False)\n",
        "\n",
        "\n",
        "def get_copyrights(project):\n",
        "\n",
        "    copyright_info_file = project / \"copr.htm\"\n",
        "\n",
        "    license_type = None\n",
        "    copyright_holder = None\n",
        "    cclink = None\n",
        "\n",
        "    with open(copyright_info_file, \"r\", encoding=\"utf-8\") as copr:\n",
        "        html = copr.read()\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    cclink = soup.find(href=regex.compile(\"creativecommons\"))\n",
        "    if cclink:\n",
        "        ref = cclink.get(\"href\")\n",
        "        if ref:\n",
        "            cc_match = regex.match(\n",
        "                r\".*?/licenses/(?P<type>.*?)/(?P<version>.*)/\", ref\n",
        "            )\n",
        "            if cc_match:\n",
        "                license_type = cc_match[\"type\"]\n",
        "            else:\n",
        "                cc_by_match = regex.match(r\".*?/licenses/by(?P<version>.*)/\", ref)\n",
        "                if cc_by_match:\n",
        "                    license_type = \"by\"\n",
        "\n",
        "    copy_strings = [s for s in soup.body.p.stripped_strings]\n",
        "      \n",
        "    for i, copy_string in enumerate(copy_strings):\n",
        "        if i == 0 and \"copyright ©\" in copy_string:\n",
        "            copyright_holder = copy_strings[i + 1]\n",
        "        if \"Public Domain\" in copy_string:\n",
        "            copyright_holder = \"Public Domain\"\n",
        "\n",
        "    return license_type, copyright_holder\n",
        "\n",
        "\n",
        "def get_extracted_projects(dir_extracted):\n",
        "\n",
        "    extracted = []\n",
        "    for line in listdir(dir_extracted):\n",
        "        m = re.search(r\".+-(.+).txt$\", line)\n",
        "        if m:\n",
        "            extracted.append(m.group(1))\n",
        "    \n",
        "    return extracted\n",
        "\n",
        "\n",
        "def get_books_type(files):\n",
        "\n",
        "    for book in files:\n",
        "        m = re.search(r\".*GEN|JON.*\", book)\n",
        "        if m:\n",
        "            return \"OT+NT\"\n",
        "    return \"NT\"\n",
        "\n",
        "\n",
        "def get_conclusion(versification):\n",
        "\n",
        "    if versification != \"\":\n",
        "        return versification\n",
        "    else:\n",
        "        return \"4\" # English\n",
        "\n",
        "\n",
        "def conclude_versification_from_OT(dan_3, dan_5, dan_13):\n",
        "    if dan_3 == 30:\n",
        "        versification = \"4\"  # English\n",
        "    elif dan_3 == 33 and dan_5 == 30:\n",
        "        versification = \"1\"  # Original\n",
        "    elif dan_3 == 33 and dan_5 == 31:\n",
        "        versification = \"5\"  # Russian Protestant\n",
        "    elif dan_3 == 97:\n",
        "        versification = \"2\"  # Septuagint\n",
        "    elif dan_3 == 100:\n",
        "        if dan_13 == 65:\n",
        "            versification = \"3\"  # Vulgate\n",
        "        else:\n",
        "            versification = \"6\"  # Russian Orthodox\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def conclude_versification_from_NT(jhn_6, act_19, rom_16):\n",
        "    if jhn_6 == 72:\n",
        "        versification = \"3\"  # Vulgate\n",
        "    elif act_19 == 41:\n",
        "        versification = \"4\"  # English\n",
        "    elif rom_16 == 24:\n",
        "        versification = \"6\"  # Russian Orthodox (same as Russian Protestant)\n",
        "    elif jhn_6 == 71 and act_19 == 40:\n",
        "        versification = \"1\"  # Original (Same as Septuagint)\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def get_last_verse(project, book, chapter):\n",
        "\n",
        "    ch = str(chapter)\n",
        "\n",
        "    for book_file in iglob(f\"{project}/*{book}*\"):\n",
        "        last_verse = \"0\"\n",
        "        try:\n",
        "            f = codecs.open(book_file, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not open {book_file}, reason:  {e}\")\n",
        "            continue\n",
        "        try:\n",
        "            in_chapter = False\n",
        "            for line in f:\n",
        "                m = re.search(r\"\\\\c ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if m.group(1) == ch:\n",
        "                        in_chapter = True\n",
        "                    else:\n",
        "                        in_chapter = False\n",
        "\n",
        "                m = re.search(r\"\\\\v ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if in_chapter:\n",
        "                        last_verse = m.group(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Something went wrong in reading {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "        try:\n",
        "            return int(last_verse)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not convert {last_verse} into an integer in {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "def get_checkpoints_OT(project):\n",
        "    dan_3 = get_last_verse(project, \"DAN\", 3)\n",
        "    dan_5 = get_last_verse(project, \"DAN\", 5)\n",
        "    dan_13 = get_last_verse(project, \"DAN\", 13)\n",
        "\n",
        "    return dan_3, dan_5, dan_13\n",
        "\n",
        "\n",
        "def get_checkpoints_NT(project):\n",
        "    jhn_6 = get_last_verse(project, \"JHN\", 6)\n",
        "    act_19 = get_last_verse(project, \"ACT\", 19)\n",
        "    rom_16 = get_last_verse(project, \"ROM\", 16)\n",
        "\n",
        "    return jhn_6, act_19, rom_16\n",
        "\n",
        "\n",
        "def get_versification(project):\n",
        "    versification = \"\"\n",
        "    books = get_books_type(listdir(project))\n",
        "\n",
        "    if books == \"OT+NT\":\n",
        "        dan_3, dan_5, dan_13 = get_checkpoints_OT(project)\n",
        "        versification = conclude_versification_from_OT(dan_3, dan_5, dan_13)\n",
        "\n",
        "    if not versification:\n",
        "        jhn_6, act_19, rom_16 = get_checkpoints_NT(project)\n",
        "        versification = conclude_versification_from_NT(jhn_6, act_19, rom_16)\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def add_settings_file(project, language_code):\n",
        "    versification = get_conclusion(get_versification(project))\n",
        "\n",
        "    root = ET.Element(\"ScriptureText\")\n",
        "    ET.SubElement(root, \"Versification\").text = versification\n",
        "    ET.SubElement(root, \"LanguageIsoCode\").text = language_code + \":::\"\n",
        "    ET.SubElement(root, \"Naming\", BookNameForm = \"41-MAT\", PostPart = project.name + \".usfm\", PrePart = \"\")\n",
        "    ET.ElementTree(root).write(project / \"Settings.xml\")\n",
        "\n",
        "\n",
        "def get_language_code(project):\n",
        "\n",
        "    translations = pd.read_csv(ebible_translations_csv)\n",
        "    improve_column_names(translations)\n",
        "    translations.set_index(\"translationid\", inplace = True)\n",
        "    language_code = translations.loc[project.name]['languagecode']\n",
        "\n",
        "    return language_code\n",
        "\n",
        "\n",
        "def is_redistributable(project, licence_type, copyright_holder):\n",
        "\n",
        "    ok_copyrights = [\"by-nc-nd\", \"by-nd\", \"by-sa\"]\n",
        "\n",
        "    translations = pd.read_csv(ebible_translations_csv)\n",
        "    improve_column_names(translations)\n",
        "    translations.set_index(\"translationid\", inplace = True)\n",
        "    redistributable = translations.loc[project.name]['redistributable']\n",
        "\n",
        "    return redistributable and (licence_type in ok_copyrights or copyright_holder == \"Public Domain\")\n",
        "\n",
        "\n",
        "def unzip(zip, unzip):\n",
        "    unzip.mkdir(parents=True, exist_ok=True)\n",
        "    shutil.unpack_archive(zip, unzip)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract projects"
      ],
      "metadata": {
        "id": "0nJMFLIvMAIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.lib import get_level_sorter\n",
        "log_file = open(ebible_logs / f\"run_{date.today()}.log\", \"a\")\n",
        "log_and_print(f\"Starting extracting eBible projects...\")\n",
        "\n",
        "# Tell the SIL NLP tools where to find the resources\n",
        "environ['SIL_NLP_DATA_PATH'] = base\n",
        "environ['SIL_NLP_MT_DIR'] = \"extractions\"\n",
        "\n",
        "# Tell Python where to find our repo\n",
        "environ['PYTHONPATH'] = \"/env/python:/content/silnlp\"\n",
        "\n",
        "makedirs(ebible_extractions, exist_ok=True)\n",
        "makedirs(ebible_temp, exist_ok=True)\n",
        "\n",
        "extracted = get_extracted_projects(ebible_extractions)\n",
        "nr_extracted = len(extracted)\n",
        "\n",
        "for download in sorted(ebible_downloads.glob(\"[a-zA-Z0-9]*\")):\n",
        "    name = download.name[0:download.name.find(\"_usfm.zip\")]\n",
        "    if not name in extracted or rewrite:\n",
        "        project = ebible_temp / name\n",
        "        unzip(download, project)\n",
        "\n",
        "        language_code = get_language_code(project)\n",
        "        licence_type, copyright_holder = get_copyrights(project)\n",
        "        write_copyrights(name, licence_type, copyright_holder)\n",
        "\n",
        "        if is_redistributable(project, licence_type, copyright_holder):\n",
        "            log_and_print(f\"extracting {project}\")\n",
        "            add_settings_file(project, language_code)\n",
        "            !python -m silnlp.common.extract_corpora \"{project}\"\n",
        "            shutil.rmtree(project)\n",
        "\n",
        "log_and_print(f\"{len(get_extracted_projects(ebible_extractions)) - nr_extracted} new eBible projects extracted\")\n",
        "log_and_print(f\"Rewrite {rewrite}\")\n",
        "log_file.close()\n",
        "shutil.rmtree(ebible_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r17FtPQpJBeJ",
        "outputId": "49bb10bd-aa5e-4d15-b06e-0e8a3c9165ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting extracting eBible projects...\n",
            "extracting /content/drive/MyDrive/eBible/temp/aai\n",
            "2022-11-30 13:08:36,398 - silnlp.common.environment - INFO - Using workspace: /content/drive/MyDrive/eBible as per environment variable SIL_NLP_DATA_PATH.\n",
            "2022-11-30 13:08:36,450 - silnlp.common.extract_corpora - INFO - Extracting /content/drive/MyDrive/eBible/temp/aai...\n",
            "2022-11-30 13:08:42,348 - silnlp.common.extract_corpora - INFO - # of Verses: 41899\n",
            "2022-11-30 13:08:42,349 - silnlp.common.extract_corpora - INFO - # of Terms: 0\n",
            "2022-11-30 13:08:42,349 - silnlp.common.extract_corpora - INFO - Done.\n",
            "extracting /content/drive/MyDrive/eBible/temp/aaz\n",
            "2022-11-30 13:08:44,399 - silnlp.common.environment - INFO - Using workspace: /content/drive/MyDrive/eBible as per environment variable SIL_NLP_DATA_PATH.\n",
            "2022-11-30 13:08:44,421 - silnlp.common.extract_corpora - INFO - Extracting /content/drive/MyDrive/eBible/temp/aaz...\n",
            "2022-11-30 13:08:49,815 - silnlp.common.extract_corpora - INFO - # of Verses: 41899\n",
            "2022-11-30 13:08:49,816 - silnlp.common.extract_corpora - INFO - # of Terms: 0\n",
            "2022-11-30 13:08:49,816 - silnlp.common.extract_corpora - INFO - Done.\n",
            "2 new eBible projects extracted\n",
            "Rewrite False\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}